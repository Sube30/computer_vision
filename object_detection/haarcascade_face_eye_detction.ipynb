{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection using Haar Cascade\n",
    "A Haar cascade is a machine learning object detection algorithm used to identify objects in images or video streams. It's based on the Haar wavelet technique, which is a mathematical concept used for signal processing. The Haar cascade operates by training a classifier on thousands of positive and negative images of a particular object.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "#### Training Phase:\n",
    "In this phase, the algorithm is trained using a large dataset of positive and negative images. Positive images contain the object you want to detect, while negative images don't contain the object. The algorithm extracts features from these images using Haar-like features, which are small, rectangular regions that are characteristic of the object.\n",
    "\n",
    "#### Feature Selection: \n",
    "Haar-like features are selected based on their ability to discriminate between positive and negative examples. These features are simple rectangular patterns, like edges or lines.\n",
    "\n",
    "#### Training the Classifier: \n",
    "Once the features are selected, the algorithm trains a classifier, typically using a machine learning technique like AdaBoost. This classifier combines the weak learners (features) into a strong classifier.\n",
    "\n",
    "#### Cascade of Classifiers: \n",
    "The trained classifier is actually a cascade of simpler classifiers arranged in a sequence. Each classifier in the cascade is trained to rule out a certain subset of the image that is unlikely to contain the object. This allows the algorithm to quickly discard regions of the image that don't contain the object, saving computational resources.\n",
    "\n",
    "#### Detection Phase:\n",
    "During this phase, the cascade of classifiers is applied to a new image. The image is scanned at multiple scales and positions, and at each step, the cascade quickly rejects regions of the image that are unlikely to contain the object. This process continues until the algorithm either detects the object or exhausts all possible locations and scales.\n",
    "\n",
    "Haar cascades are often used for real-time object detection tasks due to their efficiency and accuracy. They have been successfully applied in various domains, including face detection, pedestrian detection, and more. However, they may not perform as well with objects that have significant variations in appearance or occlusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pros:\n",
    "\n",
    "Efficiency: Haar cascades are computationally efficient, making them suitable for real-time applications such as video surveillance and robotics.\n",
    "\n",
    "Accuracy: When trained properly on a sufficient amount of data, Haar cascades can achieve high levels of accuracy in detecting objects of interest.\n",
    "\n",
    "Robustness: Haar cascades can handle various lighting conditions and backgrounds, making them robust in different environments.\n",
    "\n",
    "Resource Requirements: Compared to some other deep learning-based approaches, Haar cascades require less computational resources during both training and inference.\n",
    "\n",
    "Easy to Implement: Implementing Haar cascades for object detection is relatively straightforward, especially with libraries like OpenCV providing pre-trained models and tools for training custom cascades.\n",
    "\n",
    "#### Cons:\n",
    "\n",
    "Limited to Simple Features: Haar cascades rely on simple features like edges and lines, which may not capture complex patterns or textures well. This can lead to lower accuracy in detecting objects with intricate appearances.\n",
    "\n",
    "Sensitivity to Occlusion: Haar cascades may struggle to detect objects that are partially occluded or overlapped by other objects, as the simple features they rely on might not be present or may be distorted.\n",
    "\n",
    "Sensitive to Variations in Scale: While Haar cascades can detect objects at multiple scales, they may struggle with significant variations in object size or aspect ratio.\n",
    "\n",
    "Training Data Requirements: Training a Haar cascade requires a large dataset of positive and negative examples, which can be time-consuming and resource-intensive to collect and label.\n",
    "\n",
    "Limited Domain Specificity: Haar cascades are effective for general object detection tasks but may not perform as well for highly specialized or domain-specific objects without extensive customization and training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenCV library manages a repository(https://github.com/opencv/opencv/tree/master/data/haarcascades) that contains the preprocessed haar cascades that can be used for various applications like face detection, Eye detection, Nose / Mouth detection, Vehicle detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211 3375\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries and reading the image\n",
    "\n",
    "import cv2\n",
    "image = cv2.imread(\"image1.jpg\")\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "h,w = image.shape[:2]\n",
    "print(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a pretrained Haar Cascade for face and eye detection\n",
    "\n",
    "eye_detector = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#predict the results using detectMultiscale function\n",
    "\n",
    "face_results = face_detector.detectMultiScale(\n",
    "\t\tgray_image, scaleFactor=1.2, minNeighbors=5,\n",
    "\t\tminSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y, w, h) in face_results:\n",
    "        cv2.rectangle(image, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  3)\n",
    "        roi_gray = gray_image[y:y+h,x:x+w]\n",
    "        roi_color = image[y:y+h, x:x+w]\n",
    "        eyes = eye_detector.detectMultiScale(roi_gray)\n",
    "        for (x1,y1, w1, h1) in eyes:\n",
    "            cv2.rectangle(roi_color, (x1,y1), (x1+w1, y1+h1), (0,255,0), 5)\n",
    "        cv2.imshow(\"window\", image)\n",
    "        if cv2.waitKey(-1):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the haarcascade for video\n",
    "\n",
    "# reading the input image now\n",
    "cap = cv2.VideoCapture(\"video1.mp4\")\n",
    "while cap.isOpened():\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray,1.1, 4 )\n",
    "    for (x,y, w, h) in faces:\n",
    "        cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  3)\n",
    "        roi_gray = gray[y:y+h,x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_detector.detectMultiScale(roi_gray)\n",
    "        for (x1,y1, w1, h1) in eyes:\n",
    "            cv2.rectangle(roi_color, (x1,y1), (x1+w1, y1+h1), (0,255,0), 5)\n",
    "        cv2.imshow(\"window\", frame)\n",
    "        if cv2.waitKey(-1):\n",
    "            break\n",
    "\n",
    "frame.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
